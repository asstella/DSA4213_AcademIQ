{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install SpaCy\n",
    "# !pip install pickleshare\n",
    "# !pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/michelle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/michelle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/michelle/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PyPDF2.PdfReader('play.pdf')\n",
    "text = pdf.pages[0].extract_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation and non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess input document\n",
    "def preprocess_document(text):\n",
    "    processed_text = preprocess_text(text)\n",
    "\n",
    "    processed_document = {}\n",
    "\n",
    "    processed_document[\"Original_text\"] = text\n",
    "    processed_document[\"Processed_text\"] = processed_text\n",
    "\n",
    "    # print(f\"Original Text: {processed_document['Original_text']}\")\n",
    "    # print(f\"Processed Text: {processed_document['Processed_text']}\")\n",
    "\n",
    "    return processed_document['Processed_text']\n",
    "\n",
    "processed = preprocess_document(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(processed, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['5',\n",
       "  'c',\n",
       "  'reating',\n",
       "  'stealth',\n",
       "  'game',\n",
       "  'intervention',\n",
       "  'attitude',\n",
       "  'behavior',\n",
       "  'change',\n",
       "  'n',\n",
       "  'embedded',\n",
       "  'design',\n",
       "  'model',\n",
       "  'geoff',\n",
       "  'kaufman',\n",
       "  'mary',\n",
       "  'flanagan',\n",
       "  'max',\n",
       "  'seidman',\n",
       "  'abstract',\n",
       "  'chapter',\n",
       "  'open',\n",
       "  'example',\n",
       "  'transformational',\n",
       "  'game',\n",
       "  'utilize',\n",
       "  'overt',\n",
       "  'explicit',\n",
       "  'approach',\n",
       "  'attitude',\n",
       "  'behavior',\n",
       "  'change',\n",
       "  'acknowledging',\n",
       "  'worthwhile',\n",
       "  'intention',\n",
       "  'game',\n",
       "  'poten',\n",
       "  'tial',\n",
       "  'utility',\n",
       "  'triggering',\n",
       "  'reflection',\n",
       "  'action',\n",
       "  'overview',\n",
       "  'present',\n",
       "  'central',\n",
       "  'premise',\n",
       "  'chapter',\n",
       "  'number',\n",
       "  'fundamental',\n",
       "  'reason',\n",
       "  'explicit',\n",
       "  'approach',\n",
       "  'backfire',\n",
       "  'limited',\n",
       "  'utility',\n",
       "  'persuasion',\n",
       "  'use',\n",
       "  'implicit',\n",
       "  'covert',\n",
       "  'approach',\n",
       "  'persua',\n",
       "  'sion',\n",
       "  'effective',\n",
       "  'embedded',\n",
       "  'design',\n",
       "  'model',\n",
       "  'presented',\n",
       "  'chapter',\n",
       "  'particularly',\n",
       "  'relevant',\n",
       "  'game',\n",
       "  'attempting',\n",
       "  'engage',\n",
       "  'player',\n",
       "  'sensitive',\n",
       "  'potentially',\n",
       "  'threatening',\n",
       "  'topic',\n",
       "  'address',\n",
       "  'attitude',\n",
       "  'behavior',\n",
       "  'implicit',\n",
       "  'unconscious',\n",
       "  'keywords',\n",
       "  'embedded',\n",
       "  'design',\n",
       "  'persuasive',\n",
       "  'game',\n",
       "  'stealth',\n",
       "  'design',\n",
       "  'attitude',\n",
       "  'change',\n",
       "  'introduction',\n",
       "  'past',\n",
       "  'decade',\n",
       "  'seen',\n",
       "  'emergence',\n",
       "  'plethora',\n",
       "  'persuasive',\n",
       "  'game',\n",
       "  'aim',\n",
       "  'increase',\n",
       "  'player',\n",
       "  'awareness',\n",
       "  'critical',\n",
       "  'timely',\n",
       "  'social',\n",
       "  'suesand',\n",
       "  'change',\n",
       "  'player',\n",
       "  'attitude',\n",
       "  'behaviorsthrough',\n",
       "  'gameplay',\n",
       "  'bogost',\n",
       "  '2007',\n",
       "  'running',\n",
       "  'gamut',\n",
       "  'game',\n",
       "  'targeting',\n",
       "  'cognitive',\n",
       "  'bias',\n",
       "  'reduce',\n",
       "  'accuracy',\n",
       "  'judgment',\n",
       "  'decisionmaking',\n",
       "  'eg',\n",
       "  'sirius',\n",
       "  'initiative',\n",
       "  'intelligence',\n",
       "  'advanced',\n",
       "  'research',\n",
       "  'project',\n",
       "  'activity',\n",
       "  'program',\n",
       "  'see',\n",
       "  'dunbar',\n",
       "  'et',\n",
       "  'al',\n",
       "  '2013',\n",
       "  'one',\n",
       "  'intended',\n",
       "  'encourage',\n",
       "  'behavior',\n",
       "  'benefit',\n",
       "  'hera',\n",
       "  'dela',\n",
       "  'j',\n",
       "  'jansz',\n",
       "  'j',\n",
       "  'raessens',\n",
       "  'b',\n",
       "  'schouten',\n",
       "  'persuasive',\n",
       "  'gaming',\n",
       "  'context',\n",
       "  'amsterdam',\n",
       "  'amsterdam',\n",
       "  'university',\n",
       "  'press',\n",
       "  '2021',\n",
       "  'doi',\n",
       "  '1051179789463728805ch05']]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = make_bigrams([processed])\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 3), (16, 1), (17, 5), (18, 1), (19, 1), (20, 1), (21, 4), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 4), (29, 3), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 4), (38, 1), (39, 1), (40, 1), (41, 1), (42, 3), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 1), (50, 1), (51, 7), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 2), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 3), (85, 3), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 2), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 2), (124, 1), (125, 1)]]\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(bigrams)\n",
    "\n",
    "# Create Corpus\n",
    "texts = bigrams\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('1051179789463728805ch05', 1),\n",
       "  ('2007', 1),\n",
       "  ('2013', 1),\n",
       "  ('2021', 1),\n",
       "  ('5', 1),\n",
       "  ('abstract', 1),\n",
       "  ('accuracy', 1),\n",
       "  ('acknowledging', 1),\n",
       "  ('action', 1),\n",
       "  ('activity', 1),\n",
       "  ('address', 1),\n",
       "  ('advanced', 1),\n",
       "  ('aim', 1),\n",
       "  ('al', 1),\n",
       "  ('amsterdam', 2),\n",
       "  ('approach', 3),\n",
       "  ('attempting', 1),\n",
       "  ('attitude', 5),\n",
       "  ('awareness', 1),\n",
       "  ('b', 1),\n",
       "  ('backfire', 1),\n",
       "  ('behavior', 4),\n",
       "  ('behaviorsthrough', 1),\n",
       "  ('benefit', 1),\n",
       "  ('bias', 1),\n",
       "  ('bogost', 1),\n",
       "  ('c', 1),\n",
       "  ('central', 1),\n",
       "  ('change', 4),\n",
       "  ('chapter', 3),\n",
       "  ('cognitive', 1),\n",
       "  ('context', 1),\n",
       "  ('covert', 1),\n",
       "  ('critical', 1),\n",
       "  ('decade', 1),\n",
       "  ('decisionmaking', 1),\n",
       "  ('dela', 1),\n",
       "  ('design', 4),\n",
       "  ('doi', 1),\n",
       "  ('dunbar', 1),\n",
       "  ('effective', 1),\n",
       "  ('eg', 1),\n",
       "  ('embedded', 3),\n",
       "  ('emergence', 1),\n",
       "  ('encourage', 1),\n",
       "  ('engage', 1),\n",
       "  ('et', 1),\n",
       "  ('example', 1),\n",
       "  ('explicit', 2),\n",
       "  ('flanagan', 1),\n",
       "  ('fundamental', 1),\n",
       "  ('game', 7),\n",
       "  ('gameplay', 1),\n",
       "  ('gaming', 1),\n",
       "  ('gamut', 1),\n",
       "  ('geoff', 1),\n",
       "  ('hera', 1),\n",
       "  ('implicit', 2),\n",
       "  ('increase', 1),\n",
       "  ('initiative', 1),\n",
       "  ('intelligence', 1),\n",
       "  ('intended', 1),\n",
       "  ('intention', 1),\n",
       "  ('intervention', 1),\n",
       "  ('introduction', 1),\n",
       "  ('j', 2),\n",
       "  ('jansz', 1),\n",
       "  ('judgment', 1),\n",
       "  ('kaufman', 1),\n",
       "  ('keywords', 1),\n",
       "  ('limited', 1),\n",
       "  ('mary', 1),\n",
       "  ('max', 1),\n",
       "  ('model', 2),\n",
       "  ('n', 1),\n",
       "  ('number', 1),\n",
       "  ('one', 1),\n",
       "  ('open', 1),\n",
       "  ('overt', 1),\n",
       "  ('overview', 1),\n",
       "  ('particularly', 1),\n",
       "  ('past', 1),\n",
       "  ('persua', 1),\n",
       "  ('persuasion', 1),\n",
       "  ('persuasive', 3),\n",
       "  ('player', 3),\n",
       "  ('plethora', 1),\n",
       "  ('poten', 1),\n",
       "  ('potentially', 1),\n",
       "  ('premise', 1),\n",
       "  ('present', 1),\n",
       "  ('presented', 1),\n",
       "  ('press', 1),\n",
       "  ('program', 1),\n",
       "  ('project', 1),\n",
       "  ('raessens', 1),\n",
       "  ('reason', 1),\n",
       "  ('reating', 1),\n",
       "  ('reduce', 1),\n",
       "  ('reflection', 1),\n",
       "  ('relevant', 1),\n",
       "  ('research', 1),\n",
       "  ('running', 1),\n",
       "  ('schouten', 1),\n",
       "  ('see', 1),\n",
       "  ('seen', 1),\n",
       "  ('seidman', 1),\n",
       "  ('sensitive', 1),\n",
       "  ('sion', 1),\n",
       "  ('sirius', 1),\n",
       "  ('social', 1),\n",
       "  ('stealth', 2),\n",
       "  ('suesand', 1),\n",
       "  ('targeting', 1),\n",
       "  ('threatening', 1),\n",
       "  ('tial', 1),\n",
       "  ('timely', 1),\n",
       "  ('topic', 1),\n",
       "  ('transformational', 1),\n",
       "  ('triggering', 1),\n",
       "  ('unconscious', 1),\n",
       "  ('university', 1),\n",
       "  ('use', 1),\n",
       "  ('utility', 2),\n",
       "  ('utilize', 1),\n",
       "  ('worthwhile', 1)]]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.008*\"game\" + 0.008*\"attitude\" + 0.008*\"design\" + 0.008*\"persuasive\" + '\n",
      "  '0.008*\"approach\" + 0.008*\"behavior\" + 0.008*\"change\" + 0.008*\"player\" + '\n",
      "  '0.008*\"chapter\" + 0.008*\"embedded\"'),\n",
      " (1,\n",
      "  '0.038*\"game\" + 0.028*\"attitude\" + 0.022*\"change\" + 0.022*\"design\" + '\n",
      "  '0.022*\"behavior\" + 0.017*\"embedded\" + 0.017*\"chapter\" + 0.017*\"approach\" + '\n",
      "  '0.017*\"persuasive\" + 0.017*\"player\"'),\n",
      " (2,\n",
      "  '0.008*\"change\" + 0.008*\"game\" + 0.008*\"attitude\" + 0.008*\"behavior\" + '\n",
      "  '0.008*\"design\" + 0.008*\"chapter\" + 0.008*\"persuasive\" + 0.008*\"player\" + '\n",
      "  '0.008*\"approach\" + 0.008*\"stealth\"'),\n",
      " (3,\n",
      "  '0.008*\"game\" + 0.008*\"design\" + 0.008*\"behavior\" + 0.008*\"change\" + '\n",
      "  '0.008*\"player\" + 0.008*\"attitude\" + 0.008*\"approach\" + 0.008*\"persuasive\" + '\n",
      "  '0.008*\"chapter\" + 0.008*\"stealth\"'),\n",
      " (4,\n",
      "  '0.009*\"game\" + 0.008*\"attitude\" + 0.008*\"behavior\" + 0.008*\"design\" + '\n",
      "  '0.008*\"player\" + 0.008*\"change\" + 0.008*\"embedded\" + 0.008*\"persuasive\" + '\n",
      "  '0.008*\"approach\" + 0.008*\"stealth\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el40476109839155842006931457\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el40476109839155842006931457_data = {\"mdsDat\": {\"x\": [0.007120853872456719, -0.0018017829175788432, -0.001800946313258632, -0.0018165250259221295, -0.0017015996156971146], \"y\": [0.017076500995603743, -0.004364964454827552, -0.004289441428422548, -0.0042679487137985235, -0.004154146398555119], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [99.93218744913189, 0.02289552195562519, 0.017021352915776267, 0.016700407497001624, 0.01119526849971348]}, \"tinfo\": {\"Term\": [\"game\", \"attitude\", \"behavior\", \"design\", \"change\", \"player\", \"persuasive\", \"approach\", \"embedded\", \"chapter\", \"stealth\", \"j\", \"model\", \"implicit\", \"utility\", \"explicit\", \"amsterdam\", \"emergence\", \"awareness\", \"intention\", \"persuasion\", \"social\", \"program\", \"seen\", \"attempting\", \"behaviorsthrough\", \"central\", \"covert\", \"engage\", \"gamut\", \"game\", \"attitude\", \"change\", \"design\", \"behavior\", \"embedded\", \"chapter\", \"approach\", \"persuasive\", \"player\", \"amsterdam\", \"explicit\", \"implicit\", \"j\", \"utility\", \"model\", \"stealth\", \"emergence\", \"awareness\", \"intention\", \"persuasion\", \"social\", \"program\", \"seen\", \"attempting\", \"behaviorsthrough\", \"central\", \"covert\", \"engage\", \"gamut\", \"encourage\", \"overt\", \"reduce\", \"particularly\", \"bias\", \"transformational\", \"action\", \"university\", \"past\", \"triggering\", \"topic\", \"intervention\", \"bogost\", \"press\", \"present\", \"plethora\", \"abstract\", \"address\", \"effective\", \"reason\", \"potentially\", \"mary\", \"acknowledging\", \"seidman\", \"advanced\", \"benefit\", \"raessens\", \"example\", \"project\", \"initiative\", \"sion\", \"gaming\", \"research\", \"max\", \"activity\", \"encourage\", \"c\", \"threatening\", \"et\", \"introduction\", \"hera\", \"flanagan\", \"seen\", \"game\", \"design\", \"behavior\", \"change\", \"player\", \"attitude\", \"approach\", \"persuasive\", \"chapter\", \"stealth\", \"model\", \"utility\", \"explicit\", \"embedded\", \"implicit\", \"amsterdam\", \"j\", \"effective\", \"worthwhile\", \"action\", \"press\", \"particularly\", \"raessens\", \"fundamental\", \"bias\", \"reflection\", \"judgment\", \"overt\", \"reduce\", \"potentially\", \"sion\", \"timely\", \"2007\", \"b\", \"see\", \"intelligence\", \"reason\", \"transformational\", \"2021\", \"targeting\", \"plethora\", \"acknowledging\", \"example\", \"unconscious\", \"dunbar\", \"abstract\", \"mary\", \"aim\", \"al\", \"central\", \"introduction\", \"engage\", \"game\", \"design\", \"persuasive\", \"attitude\", \"approach\", \"model\", \"stealth\", \"player\", \"behavior\", \"change\", \"chapter\", \"embedded\", \"amsterdam\", \"implicit\", \"utility\", \"explicit\", \"j\", \"press\", \"intended\", \"overt\", \"university\", \"2021\", \"intelligence\", \"kaufman\", \"particularly\", \"reduce\", \"jansz\", \"b\", \"presented\", \"suesand\", \"triggering\", \"project\", \"reating\", \"encourage\", \"worthwhile\", \"c\", \"accuracy\", \"increase\", \"eg\", \"action\", \"address\", \"seidman\", \"benefit\", \"bogost\", \"initiative\", \"dunbar\", \"plethora\", \"number\", \"backfire\", \"gamut\", \"change\", \"game\", \"attitude\", \"behavior\", \"chapter\", \"design\", \"persuasive\", \"stealth\", \"player\", \"approach\", \"embedded\", \"model\", \"utility\", \"amsterdam\", \"j\", \"implicit\", \"explicit\", \"effective\", \"intervention\", \"overt\", \"advanced\", \"initiative\", \"university\", \"plethora\", \"transformational\", \"tial\", \"geoff\", \"utilize\", \"bogost\", \"decade\", \"1051179789463728805ch05\", \"topic\", \"see\", \"particularly\", \"action\", \"one\", \"benefit\", \"address\", \"sion\", \"timely\", \"kaufman\", \"research\", \"gameplay\", \"example\", \"2007\", \"reduce\", \"reating\", \"5\", \"use\", \"behavior\", \"game\", \"attitude\", \"design\", \"player\", \"stealth\", \"embedded\", \"j\", \"change\", \"explicit\", \"implicit\", \"utility\", \"model\", \"persuasive\", \"approach\", \"chapter\", \"amsterdam\"], \"Freq\": [6.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 6.2260505436015885, 4.493550118173081, 3.63100678430032, 3.6277057835130573, 3.62638863987199, 2.7681218012184634, 2.767743062112882, 2.766942161583881, 2.7664403925777603, 2.764176099628865, 1.9034414259115806, 1.9026274082240666, 1.902281235856863, 1.9020565856708294, 1.902148405780423, 1.9015383825235825, 1.9001910844951282, 1.0394503045143977, 1.0389803483869704, 1.0388635001358453, 1.0389042839447864, 1.0387851741146075, 1.0387667045523328, 1.0387215483572207, 1.0386646319510278, 1.0386586010735503, 1.0387137836024687, 1.0385894721404654, 1.0384917719253313, 1.038433046255895, 1.0384601852045434, 0.00029425990530817684, 0.00029439231033944054, 0.0002943230507287743, 0.0002945774977572868, 0.0002943294412664168, 0.00029429289429979094, 0.0002942512003596043, 0.0002944933153776391, 0.00029438405445567534, 0.00029438961595059667, 0.00029427320453516263, 0.00029434999461721304, 0.0002941925801305267, 0.00029433206656836726, 0.0002941840478991878, 0.0002942906489757544, 0.00029424974953484224, 0.0002940787594735964, 0.00029428785095657036, 0.00029434218779825515, 0.00029431092597897686, 0.0002943444676657384, 0.0002942613215894922, 0.00029419983425433714, 0.0002942176932162895, 0.0002942686448001961, 0.00029425679639797237, 0.00029431783466832013, 0.0002941153064402223, 0.0002942058448140658, 0.000294282289461649, 0.0002942655358899916, 0.00029424156273797047, 0.0002942686448001961, 0.0002943765930711846, 0.00029426208154531997, 0.00029428992356337334, 0.0002942570727455461, 0.00029427323907860935, 0.00029428232400509574, 0.0002942716846235071, 0.0002942753116854123, 0.00029796703892288017, 0.0002966655109375022, 0.00029628194050516406, 0.0002959789599340151, 0.0002959518778717895, 0.00029590738591241887, 0.00029588362002107803, 0.0002956891749595118, 0.0002955015349569487, 0.0002950595170127665, 0.00029497253661393477, 0.0002948643119953725, 0.0002948012356616685, 0.0002947291434883715, 0.00029467698288382984, 0.00029467301038745746, 0.0002944508614816247, 0.00021906579437830603, 0.00021919453242078045, 0.0002188759873023179, 0.00021874080336942636, 0.0002187230322293122, 0.00021886111809693337, 0.00021889971639692122, 0.00021888107210830433, 0.0002188578052687907, 0.0002188766293232758, 0.00021860633850000763, 0.00021869943153890047, 0.000218823290222095, 0.00021874434732511387, 0.00021870700738620347, 0.00021870803461973608, 0.0002187193341885948, 0.00021869052028800507, 0.00021870112647422927, 0.0002186855382053719, 0.00021858982572097092, 0.00021865913830358382, 0.00021878957128138705, 0.00021857318453774263, 0.00021872845088619672, 0.00021867200440357976, 0.00021870156304848063, 0.00021861029334910818, 0.0002186079563928215, 0.00021865410485927403, 0.00021872547190895215, 0.00021871419802093174, 0.00021876568810175385, 0.00021867310867962732, 0.0002186574176874167, 0.00022567475811873937, 0.00022337324138892536, 0.00022262580058975958, 0.00022367717411038652, 0.00022252497761853385, 0.00022040782362698513, 0.00022031141775994962, 0.00022111612682855844, 0.00022136844106500591, 0.0002213340801033401, 0.00022066406703169484, 0.0002206414422131391, 0.00021985437588045286, 0.00021984664594811997, 0.00021983416506069875, 0.00021970727603858303, 0.00021967463569308432, 0.00021511924438701252, 0.0002148780371980675, 0.00021467628790715733, 0.00021472307801996115, 0.0002147371629273695, 0.00021472516933895023, 0.00021469304365568428, 0.00021461390109008558, 0.00021460205868135225, 0.00021475941153781958, 0.0002146528298592196, 0.0002146981585683925, 0.00021472537091186484, 0.00021462193881005565, 0.00021467767372094528, 0.00021464083627080032, 0.00021475371710298185, 0.00021457456917512233, 0.00021463315130343082, 0.000214634864673205, 0.00021458583206172615, 0.00021459963980637693, 0.00021444090113612166, 0.00021451520595176972, 0.00021454473638376007, 0.00021450157458341923, 0.00021445251677532605, 0.00021439383386056025, 0.00021445763168803427, 0.00021436808292071884, 0.00021446224266845598, 0.0002144635276957866, 0.00021445874033906463, 0.0002220128364937555, 0.0002215985789576179, 0.00022041705931863213, 0.00021984340800026677, 0.00021781626478787827, 0.00021782750247786777, 0.00021708042286309494, 0.0002162255773288488, 0.00021669693039304966, 0.00021658336925228132, 0.00021595436097224122, 0.00021587055703299217, 0.00021557230470921254, 0.00021552503586073652, 0.00021544244135897513, 0.00021522645598097065, 0.00021474923210563178, 0.00014417984333479209, 0.0001441413492534871, 0.00014390700661021154, 0.0001439605672648048, 0.00014392008007178678, 0.00014388455876727414, 0.00014377409308419627, 0.00014375617196955625, 0.0001438104758183476, 0.00014377345123466157, 0.00014377765703819158, 0.00014374091959771845, 0.0001437137085556025, 0.00014374708473140706, 0.00014367612657626788, 0.00014363771694884906, 0.00014356952888117547, 0.0001435187045324933, 0.00014363263282490314, 0.00014357361644926487, 0.00014354701347512916, 0.0001435528407932732, 0.00014352382243799369, 0.0001435122522555918, 0.00014353535883884113, 0.00014353275765914786, 0.00014349723635463522, 0.0001434599921908452, 0.0001434157890268368, 0.00014348546348290657, 0.00014347968683709424, 0.00014350519191071008, 0.00015276670909937862, 0.00015487602935974017, 0.0001528663646850299, 0.000151545168090175, 0.00014935455251901012, 0.00014623616033620894, 0.0001475393682533149, 0.0001459482063660084, 0.00014774280077426138, 0.00014575457049585477, 0.0001456879701612407, 0.000145484520749517, 0.00014535643798578926, 0.00014640393642642493, 0.00014629814948863949, 0.00014622472528002487, 0.00014454419429039956], \"Total\": [6.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 6.226950660006947, 4.494442986157107, 3.6318938529776252, 3.6285951949359516, 3.62727890037066, 2.7690006655333907, 2.7686232687049386, 2.767823451700262, 2.7673221919125996, 2.765059219116477, 1.9043160225279996, 1.9035024205383684, 1.9031566739118373, 1.902932101815729, 1.903024161082938, 1.9024149898788423, 1.9010689171675659, 1.0403191624757884, 1.0398496166917601, 1.0397327693759466, 1.03977372178235, 1.0396546805558575, 1.0396362821759215, 1.0395910897668315, 1.0395341787471706, 1.0395281745390306, 1.0395834899465861, 1.039459145923316, 1.0393615647381325, 1.0393027967182664, 1.039330140810408, 1.0376508291899136, 1.0381628876688491, 1.0379860767241984, 1.038896167638448, 1.0381566724255589, 1.0380852590190117, 1.0379416154536194, 1.0388999443494564, 1.0385214933072533, 1.0385693288219306, 1.0381704628997628, 1.0384486641147916, 1.0380345436845189, 1.0385796942422645, 1.0381373478022995, 1.0385245217325003, 1.0384529571211236, 1.037862526678546, 1.0386079187128217, 1.0388123409604217, 1.0387471898009981, 1.0389066450884854, 1.038617564676092, 1.0384103396982725, 1.0385030038854532, 1.0386933198495243, 1.0386697614246976, 1.0388893969870912, 1.0381770807178705, 1.0385171756634586, 1.0387998753592982, 1.0387409631335875, 1.0386542178960565, 1.0387885943026145, 1.039330140810408, 1.0387951151207984, 1.0390480439692007, 1.0387898581582562, 1.0390162179702276, 1.039288526802052, 1.0392105826855211, 1.0395910897668315, 6.226950660006947, 3.6285951949359516, 3.62727890037066, 3.6318938529776252, 2.765059219116477, 4.494442986157107, 2.767823451700262, 2.7673221919125996, 2.7686232687049386, 1.9010689171675659, 1.9024149898788423, 1.903024161082938, 1.9035024205383684, 2.7690006655333907, 1.9031566739118373, 1.9043160225279996, 1.902932101815729, 1.037862526678546, 1.0384842288606002, 1.0380852590190117, 1.0380345436845189, 1.0379860767241984, 1.0386933198495243, 1.0388861731712582, 1.038896167638448, 1.0387923013565419, 1.0389316225350274, 1.0376508291899136, 1.0381628876688491, 1.0388123409604217, 1.0385171756634586, 1.0383503234167566, 1.0384136796856767, 1.0385015283525243, 1.0384350421567454, 1.0384996648773062, 1.0386079187128217, 1.0381566724255589, 1.0385268261795735, 1.0391613325666869, 1.0381373478022995, 1.0389066450884854, 1.0386697614246976, 1.0389307333761624, 1.0385310446225544, 1.0385245217325003, 1.0387471898009981, 1.03922464233261, 1.0392207109613214, 1.0395834899465861, 1.0390162179702276, 1.0393615647381325, 6.226950660006947, 3.6285951949359516, 2.7673221919125996, 4.494442986157107, 2.767823451700262, 1.9024149898788423, 1.9010689171675659, 2.765059219116477, 3.62727890037066, 3.6318938529776252, 2.7686232687049386, 2.7690006655333907, 1.9043160225279996, 1.9031566739118373, 1.903024161082938, 1.9035024205383684, 1.902932101815729, 1.0380345436845189, 1.038329431569335, 1.0376508291899136, 1.0379416154536194, 1.0385268261795735, 1.0384996648773062, 1.0383529393892725, 1.0379860767241984, 1.0381628876688491, 1.0389540863113433, 1.0385015283525243, 1.038723973174124, 1.0389036288172395, 1.0385214933072533, 1.0388893969870912, 1.0387344037866448, 1.039330140810408, 1.0384842288606002, 1.0387951151207984, 1.038856856632748, 1.0386944554602344, 1.038788867970776, 1.0380852590190117, 1.0384529571211236, 1.038617564676092, 1.0385030038854532, 1.0384486641147916, 1.0381770807178705, 1.0385310446225544, 1.0381373478022995, 1.0388046600620688, 1.0388250683925841, 1.0393027967182664, 3.6318938529776252, 6.226950660006947, 4.494442986157107, 3.62727890037066, 2.7686232687049386, 3.6285951949359516, 2.7673221919125996, 1.9010689171675659, 2.765059219116477, 2.767823451700262, 2.7690006655333907, 1.9024149898788423, 1.903024161082938, 1.9043160225279996, 1.902932101815729, 1.9031566739118373, 1.9035024205383684, 1.037862526678546, 1.0381704628997628, 1.0376508291899136, 1.0384103396982725, 1.0381770807178705, 1.0379416154536194, 1.0381373478022995, 1.0381566724255589, 1.0385734891778025, 1.0385546203364706, 1.0386316131608635, 1.0384486641147916, 1.0385010249804512, 1.0388312868679346, 1.0385693288219306, 1.0384350421567454, 1.0379860767241984, 1.0380852590190117, 1.0389107254240109, 1.0385030038854532, 1.0384529571211236, 1.0385171756634586, 1.0383503234167566, 1.0383529393892725, 1.0387409631335875, 1.0388619096838139, 1.0386697614246976, 1.0384136796856767, 1.0381628876688491, 1.0387344037866448, 1.0387066419871052, 1.0390430714211885, 3.62727890037066, 6.226950660006947, 4.494442986157107, 3.6285951949359516, 2.765059219116477, 1.9010689171675659, 2.7690006655333907, 1.902932101815729, 3.6318938529776252, 1.9035024205383684, 1.9031566739118373, 1.903024161082938, 1.9024149898788423, 2.7673221919125996, 2.767823451700262, 2.7686232687049386, 1.9043160225279996], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.2582, -3.5843, -3.7974, -3.7983, -3.7987, -4.0687, -4.0689, -4.0692, -4.0694, -4.0702, -4.4433, -4.4437, -4.4439, -4.444, -4.4439, -4.4443, -4.445, -5.0482, -5.0487, -5.0488, -5.0488, -5.0489, -5.0489, -5.0489, -5.049, -5.049, -5.0489, -5.0491, -5.0491, -5.0492, -5.0492, -4.8367, -4.8362, -4.8364, -4.8356, -4.8364, -4.8365, -4.8367, -4.8359, -4.8362, -4.8362, -4.8366, -4.8364, -4.8369, -4.8364, -4.8369, -4.8366, -4.8367, -4.8373, -4.8366, -4.8364, -4.8365, -4.8364, -4.8367, -4.8369, -4.8368, -4.8366, -4.8367, -4.8365, -4.8372, -4.8368, -4.8366, -4.8366, -4.8367, -4.8366, -4.8363, -4.8367, -4.8366, -4.8367, -4.8366, -4.8366, -4.8366, -4.8366, -4.8241, -4.8285, -4.8298, -4.8308, -4.8309, -4.8311, -4.8312, -4.8318, -4.8324, -4.8339, -4.8342, -4.8346, -4.8348, -4.8351, -4.8352, -4.8353, -4.836, -4.8353, -4.8347, -4.8361, -4.8368, -4.8368, -4.8362, -4.836, -4.8361, -4.8362, -4.8361, -4.8374, -4.837, -4.8364, -4.8367, -4.8369, -4.8369, -4.8369, -4.837, -4.8369, -4.837, -4.8375, -4.8371, -4.8365, -4.8375, -4.8368, -4.8371, -4.8369, -4.8374, -4.8374, -4.8372, -4.8368, -4.8369, -4.8366, -4.8371, -4.8371, -4.8056, -4.8158, -4.8192, -4.8144, -4.8196, -4.8292, -4.8296, -4.826, -4.8248, -4.825, -4.828, -4.8281, -4.8317, -4.8317, -4.8318, -4.8324, -4.8325, -4.8344, -4.8355, -4.8365, -4.8363, -4.8362, -4.8363, -4.8364, -4.8368, -4.8368, -4.8361, -4.8366, -4.8364, -4.8363, -4.8367, -4.8365, -4.8366, -4.8361, -4.837, -4.8367, -4.8367, -4.8369, -4.8368, -4.8376, -4.8372, -4.8371, -4.8373, -4.8375, -4.8378, -4.8375, -4.8379, -4.8375, -4.8375, -4.8375, -4.8029, -4.8047, -4.8101, -4.8127, -4.822, -4.8219, -4.8253, -4.8293, -4.8271, -4.8276, -4.8305, -4.8309, -4.8323, -4.8325, -4.8329, -4.8339, -4.8361, -4.8346, -4.8349, -4.8365, -4.8361, -4.8364, -4.8367, -4.8374, -4.8376, -4.8372, -4.8374, -4.8374, -4.8377, -4.8378, -4.8376, -4.8381, -4.8384, -4.8389, -4.8392, -4.8384, -4.8388, -4.839, -4.839, -4.8392, -4.8393, -4.8391, -4.8391, -4.8394, -4.8396, -4.8399, -4.8394, -4.8395, -4.8393, -4.7768, -4.763, -4.7761, -4.7848, -4.7993, -4.8204, -4.8116, -4.8224, -4.8102, -4.8237, -4.8242, -4.8256, -4.8265, -4.8193, -4.82, -4.8205, -4.8321], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.0005, 0.0005, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, 0.214, 0.2139, 0.2139, 0.2139, 0.2137, 0.2137, 0.2137, 0.2136, 0.2136, 0.2135, 0.2135, 0.2135, 0.2134, 0.2133, 0.2133, 0.2132, 0.2132, 0.2132, 0.2132, 0.2131, 0.2131, 0.2131, 0.2131, 0.213, 0.213, 0.213, 0.213, 0.213, 0.213, 0.213, 0.2129, 0.2129, 0.2129, 0.2129, 0.2128, 0.2129, 0.2127, 0.2129, 0.2127, 0.2125, 0.2125, 0.2122, -1.5654, -1.0298, -1.0307, -1.033, -0.7604, -1.2463, -0.7616, -0.7621, -0.7632, -0.3888, -0.3898, -0.3905, -0.3909, -0.766, -0.3912, -0.3918, -0.3918, 0.2152, 0.2151, 0.2141, 0.2135, 0.2135, 0.2134, 0.2134, 0.2133, 0.2133, 0.2133, 0.2133, 0.2132, 0.2131, 0.2131, 0.213, 0.213, 0.213, 0.2129, 0.2129, 0.2127, 0.2127, 0.2127, 0.2126, 0.2126, 0.2126, 0.2126, 0.2125, 0.2124, 0.2124, 0.2124, 0.2123, 0.2122, 0.2121, 0.2122, 0.2118, -1.5468, -1.0171, -0.7494, -1.2297, -0.7501, -0.3847, -0.3844, -0.7554, -1.0257, -1.0271, -0.7588, -0.759, -0.3882, -0.3876, -0.3876, -0.3885, -0.3883, 0.2158, 0.2144, 0.2142, 0.2141, 0.2136, 0.2136, 0.2136, 0.2135, 0.2133, 0.2133, 0.2132, 0.2132, 0.2132, 0.2131, 0.213, 0.2129, 0.2129, 0.2129, 0.2129, 0.2128, 0.2127, 0.2127, 0.2126, 0.2126, 0.2126, 0.2125, 0.2123, 0.2123, 0.2123, 0.2122, 0.212, 0.212, 0.2115, -1.005, -1.546, -1.2253, -1.0136, -0.7527, -1.0232, -0.7556, -0.3841, -0.7566, -0.7581, -0.7614, -0.3865, -0.3882, -0.3891, -0.3887, -0.3898, -0.3922, 0.2158, 0.2153, 0.2141, 0.2138, 0.2137, 0.2137, 0.2127, 0.2126, 0.2126, 0.2123, 0.2123, 0.2122, 0.212, 0.2119, 0.2116, 0.2115, 0.2115, 0.211, 0.211, 0.211, 0.2109, 0.2108, 0.2108, 0.2107, 0.2105, 0.2104, 0.2103, 0.2103, 0.2102, 0.2102, 0.2101, 0.21, -0.9776, -1.5043, -1.1914, -0.986, -0.7288, -0.3753, -0.7425, -0.3782, -1.0124, -0.3798, -0.3801, -0.3815, -0.382, -0.7496, -0.7505, -0.7513, -0.3886]}, \"token.table\": {\"Topic\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [0.9626202181636149, 0.963007344339585, 0.9629024256202393, 0.9627357326674477, 0.9629045622647094, 0.9625965248391438, 0.9625503934617998, 0.9633120124882592, 0.9626597803293604, 0.9629709204856753, 0.9630104417975718, 0.9622558581323019, 0.9622594983456011, 1.0502458501320484, 1.0838841610931191, 0.9619693324611832, 0.8899879278299908, 0.961677519468113, 0.9629258818582549, 0.9626259804717076, 1.102755015499705, 0.9619748886974044, 0.9629245137073286, 0.9625601009513162, 0.9629749014626866, 0.962653737434752, 0.9619237027815631, 1.1013537735197247, 1.0835710419364102, 0.962038771722706, 0.9629263485982829, 1.1023549845357175, 0.9628985143756024, 0.9635187457825298, 0.962659526717351, 1.0834233582324229, 0.9612434684180619, 0.9621581831738847, 0.9621290934035552, 0.9626586090982545, 0.9627699170026324, 1.0506947500672676, 0.962268876646547, 0.962569361133611, 0.96355348349481, 0.9625918427448727, 0.9626493261313896, 0.9621834975886044, 0.9628766560934661, 0.9621967088168047, 1.0508856298673017, 0.962747028005373, 0.9632268122395149, 0.9629276097245012, 0.9630854809620452, 0.961785594773747, 0.963232952329286, 0.9624488845357507, 1.0510096487897027, 0.962506441021235, 0.9625272523325136, 0.9630636771618034, 0.9626981519840057, 0.9627843249177227, 1.0512953328481567, 0.9626448921977783, 0.9625466130324815, 0.9637153191316704, 0.9634040594801816, 0.9625566017583965, 0.9617477139986083, 1.0840804907962625, 1.0849677212188584, 0.9632636780836034, 0.9626377744756688, 0.9628534098479445, 0.9627196693498932, 0.9633590770982297, 0.9618748567595542, 0.9625663741492836, 0.9627480805834683, 0.9628272440280741, 0.9627100020511106, 0.963239980814049, 0.9626563449633929, 0.9627039228175647, 0.9629875335515268, 0.9619166707405011, 0.9628183019530048, 0.9629113734793535, 0.9618578348200617, 1.0520397140466813, 0.9625531880550555, 0.9623144825164347, 0.9624194047658896, 0.9628591625149805, 0.9630661034605715, 0.9628630195870693, 0.9632457475455903, 0.9629073701839539, 0.9625280761021949, 0.9634453278597588, 0.9624240106160509, 1.050958805936482, 0.9628052789156917, 0.9629419226685568], \"Term\": [\"1051179789463728805ch05\", \"2007\", \"2021\", \"5\", \"abstract\", \"accuracy\", \"acknowledging\", \"action\", \"activity\", \"address\", \"advanced\", \"aim\", \"al\", \"amsterdam\", \"approach\", \"attempting\", \"attitude\", \"awareness\", \"b\", \"backfire\", \"behavior\", \"behaviorsthrough\", \"benefit\", \"bias\", \"bogost\", \"c\", \"central\", \"change\", \"chapter\", \"covert\", \"decade\", \"design\", \"dunbar\", \"effective\", \"eg\", \"embedded\", \"emergence\", \"encourage\", \"engage\", \"et\", \"example\", \"explicit\", \"flanagan\", \"fundamental\", \"game\", \"gameplay\", \"gaming\", \"gamut\", \"geoff\", \"hera\", \"implicit\", \"increase\", \"initiative\", \"intelligence\", \"intended\", \"intention\", \"intervention\", \"introduction\", \"j\", \"jansz\", \"judgment\", \"kaufman\", \"mary\", \"max\", \"model\", \"number\", \"one\", \"overt\", \"particularly\", \"past\", \"persuasion\", \"persuasive\", \"player\", \"plethora\", \"potentially\", \"present\", \"presented\", \"press\", \"program\", \"project\", \"raessens\", \"reason\", \"reating\", \"reduce\", \"reflection\", \"research\", \"see\", \"seen\", \"seidman\", \"sion\", \"social\", \"stealth\", \"suesand\", \"targeting\", \"threatening\", \"tial\", \"timely\", \"topic\", \"transformational\", \"triggering\", \"unconscious\", \"university\", \"use\", \"utility\", \"utilize\", \"worthwhile\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 4, 1, 3, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el40476109839155842006931457\", ldavis_el40476109839155842006931457_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el40476109839155842006931457\", ldavis_el40476109839155842006931457_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el40476109839155842006931457\", ldavis_el40476109839155842006931457_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.007121  0.017077       1        1  99.932187\n",
       "3     -0.001802 -0.004365       2        1   0.022896\n",
       "0     -0.001801 -0.004289       3        1   0.017021\n",
       "2     -0.001817 -0.004268       4        1   0.016700\n",
       "4     -0.001702 -0.004154       5        1   0.011195, topic_info=          Term      Freq     Total Category  logprob  loglift\n",
       "51        game  6.000000  6.000000  Default  30.0000  30.0000\n",
       "17    attitude  4.000000  4.000000  Default  29.0000  29.0000\n",
       "21    behavior  3.000000  3.000000  Default  28.0000  28.0000\n",
       "37      design  3.000000  3.000000  Default  27.0000  27.0000\n",
       "28      change  3.000000  3.000000  Default  26.0000  26.0000\n",
       "..         ...       ...       ...      ...      ...      ...\n",
       "73       model  0.000145  1.902415   Topic5  -4.8265  -0.3820\n",
       "84  persuasive  0.000146  2.767322   Topic5  -4.8193  -0.7496\n",
       "15    approach  0.000146  2.767823   Topic5  -4.8200  -0.7505\n",
       "29     chapter  0.000146  2.768623   Topic5  -4.8205  -0.7513\n",
       "14   amsterdam  0.000145  1.904316   Topic5  -4.8321  -0.3886\n",
       "\n",
       "[271 rows x 6 columns], token_table=      Topic      Freq                     Term\n",
       "term                                          \n",
       "0         1  0.962620  1051179789463728805ch05\n",
       "1         1  0.963007                     2007\n",
       "3         1  0.962902                     2021\n",
       "4         1  0.962736                        5\n",
       "5         1  0.962905                 abstract\n",
       "...     ...       ...                      ...\n",
       "121       1  0.963445               university\n",
       "122       1  0.962424                      use\n",
       "123       1  1.050959                  utility\n",
       "124       1  0.962805                  utilize\n",
       "125       1  0.962942               worthwhile\n",
       "\n",
       "[106 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 4, 1, 3, 5])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds')   \n",
    "# vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qf2103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
